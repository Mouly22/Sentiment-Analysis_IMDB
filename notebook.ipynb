{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":7110547,"sourceType":"datasetVersion","datasetId":4099844},{"sourceId":7110556,"sourceType":"datasetVersion","datasetId":4099851}],"dockerImageVersionId":30615,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/abiraazmary/imdb-sentiment-analysis?scriptVersionId=155302047\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"# **Importing Dataset CSV**","metadata":{}},{"cell_type":"code","source":"import pandas as pd\n\n# Update the file path to your CSV file\nfilepath_dict = {'yelp': '/kaggle/input/idmb-dataset/IMDB Dataset.csv'}\n\ndf_list = []\nfor source, filepath in filepath_dict.items():\n    df = pd.read_csv(filepath)  # Use pandas read_csv directly without specifying names and sep\n    df_list.append(df)\n\ndf = pd.concat(df_list)\nprint(df.iloc[0]) ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(df)","metadata":{"execution":{"iopub.status.busy":"2023-12-16T19:28:56.68447Z","iopub.execute_input":"2023-12-16T19:28:56.684926Z","iopub.status.idle":"2023-12-16T19:28:56.700262Z","shell.execute_reply.started":"2023-12-16T19:28:56.684888Z","shell.execute_reply":"2023-12-16T19:28:56.699338Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Data Splitting**","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n# Assuming 'review' is the feature and 'sentiment' is the target\nX = df['review']\ny = df['sentiment']\n\n# Perform train-test split (80% train, 20% test)\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Print the shapes of the resulting sets\nprint(\"Training set shape:\", X_train.shape, y_train.shape)\nprint(\"Testing set shape:\", X_test.shape, y_test.shape)","metadata":{"execution":{"iopub.status.busy":"2023-12-16T19:28:56.701476Z","iopub.execute_input":"2023-12-16T19:28:56.703441Z","iopub.status.idle":"2023-12-16T19:28:58.079936Z","shell.execute_reply.started":"2023-12-16T19:28:56.703392Z","shell.execute_reply":"2023-12-16T19:28:58.078454Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Tokenization**","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nimport numpy as np\n\ntokenizer = Tokenizer()\ntokenizer.fit_on_texts(X_train)\n\nX_train_tokenize = tokenizer.texts_to_sequences(X_train)\nX_test_tokenize = tokenizer.texts_to_sequences(X_test)\n\nvocab_size = len(tokenizer.word_index) + 1  # Adding 1 because of reserved 0 index\n\nprint(X_train[2])\nprint(X_train_tokenize[2])","metadata":{"execution":{"iopub.status.busy":"2023-12-16T19:28:58.08294Z","iopub.execute_input":"2023-12-16T19:28:58.083371Z","iopub.status.idle":"2023-12-16T19:29:26.057253Z","shell.execute_reply.started":"2023-12-16T19:28:58.083332Z","shell.execute_reply":"2023-12-16T19:29:26.055762Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for word in ['the', 'all', 'happy', 'sad']:\n    print('{}: {}'.format(word, tokenizer.word_index[word]))","metadata":{"execution":{"iopub.status.busy":"2023-12-16T19:29:26.058551Z","iopub.execute_input":"2023-12-16T19:29:26.059123Z","iopub.status.idle":"2023-12-16T19:29:26.065865Z","shell.execute_reply.started":"2023-12-16T19:29:26.059094Z","shell.execute_reply":"2023-12-16T19:29:26.064204Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Padding**","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\n# Calculate the lengths of sentences\nsentence_lengths = [len(seq) for seq in X_train_tokenize]\n\n# Plot the histogram\nplt.hist(sentence_lengths, bins=50, alpha=0.75)\nplt.axvline(x=np.mean(sentence_lengths), color='red', linestyle='dashed', linewidth=2, label='Mean Length')\nplt.title('Distribution of Sentence Lengths')\nplt.xlabel('Sentence Length')\nplt.ylabel('Frequency')\nplt.legend()\nplt.show()\n\nprint(\"Average sequence length:\", np.mean(sentence_lengths))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.preprocessing.sequence import pad_sequences\n\nval = 235\n\n# Pad sequences\nX_train_pad = pad_sequences(X_train_tokenize, padding='post', maxlen=val)\nX_test_pad = pad_sequences(X_test_tokenize, padding='post', maxlen=val)\n\nprint(\"Padded sequence example:\")\nprint(X_train_pad[0, :])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Encoding labels**","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\nlabel_encoder = LabelEncoder()\ny_train_encoded = label_encoder.fit_transform(y_train)\ny_test_encoded = label_encoder.fit_transform(y_test)\n\n","metadata":{"execution":{"iopub.status.busy":"2023-12-16T19:29:26.067063Z","iopub.execute_input":"2023-12-16T19:29:26.067342Z","iopub.status.idle":"2023-12-16T19:29:26.091495Z","shell.execute_reply.started":"2023-12-16T19:29:26.067318Z","shell.execute_reply":"2023-12-16T19:29:26.089714Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Embedding**","metadata":{}},{"cell_type":"code","source":"import numpy as np\n\ndef create_embedding_matrix(filepath, word_index, embedding_dim):\n    vocab_size = len(word_index) + 1\n    embedding_matrix = np.zeros((vocab_size, embedding_dim))\n\n    with open(filepath, encoding='utf-8') as f:\n        for line in f:\n            word, *vector = line.split()\n            if word in word_index:\n                idx = word_index[word]\n                embedding_matrix[idx] = np.array(vector, dtype=np.float32)[:embedding_dim]\n\n    return embedding_matrix","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"embedding_dim = 100\nembedding_matrix = create_embedding_matrix(\n    'glove.6B.100d.txt',\n    tokenizer.word_index, embedding_dim)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"nonzero_elements = np.count_nonzero(np.count_nonzero(embedding_matrix, axis=1))\nnonzero_elements / vocab_size","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(embedding_matrix)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Observations before traning**","metadata":{}},{"cell_type":"code","source":"X_test_pad","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train_pad","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_train","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_train_encoded","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train_pad","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_train_encoded","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Shallow Model**","metadata":{}},{"cell_type":"markdown","source":"Model compiling","metadata":{}},{"cell_type":"code","source":"from keras.models import Sequential\nfrom keras import layers\n\nembedding_dim = 100\n\nmodel = Sequential()\nmodel.add(layers.Embedding(vocab_size, embedding_dim, weights=[embedding_matrix], input_length=val, trainable=True))\nmodel.add(layers.Flatten())  # Flatten the 3D tensor to 2D\nmodel.add(layers.Dense(10, activation='relu'))\nmodel.add(layers.Dense(1, activation='sigmoid'))\nmodel.compile(optimizer='adam',\n              loss='binary_crossentropy',\n              metrics=['accuracy'])\nmodel.summary()\n","metadata":{"execution":{"iopub.status.busy":"2023-12-16T19:29:33.220818Z","iopub.execute_input":"2023-12-16T19:29:33.221227Z","iopub.status.idle":"2023-12-16T19:29:33.698398Z","shell.execute_reply.started":"2023-12-16T19:29:33.221193Z","shell.execute_reply":"2023-12-16T19:29:33.697319Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Fitting**","metadata":{}},{"cell_type":"code","source":"X_test_pad","metadata":{"execution":{"iopub.status.busy":"2023-12-16T19:29:33.699655Z","iopub.execute_input":"2023-12-16T19:29:33.700408Z","iopub.status.idle":"2023-12-16T19:29:33.707342Z","shell.execute_reply.started":"2023-12-16T19:29:33.70038Z","shell.execute_reply":"2023-12-16T19:29:33.705923Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train_pad","metadata":{"execution":{"iopub.status.busy":"2023-12-16T19:29:33.708804Z","iopub.execute_input":"2023-12-16T19:29:33.709124Z","iopub.status.idle":"2023-12-16T19:29:33.721405Z","shell.execute_reply.started":"2023-12-16T19:29:33.709099Z","shell.execute_reply":"2023-12-16T19:29:33.720066Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_train","metadata":{"execution":{"iopub.status.busy":"2023-12-16T19:29:33.723561Z","iopub.execute_input":"2023-12-16T19:29:33.724057Z","iopub.status.idle":"2023-12-16T19:29:33.734024Z","shell.execute_reply.started":"2023-12-16T19:29:33.724027Z","shell.execute_reply":"2023-12-16T19:29:33.73218Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_train_encoded","metadata":{"execution":{"iopub.status.busy":"2023-12-16T19:29:33.735842Z","iopub.execute_input":"2023-12-16T19:29:33.736109Z","iopub.status.idle":"2023-12-16T19:29:33.74735Z","shell.execute_reply.started":"2023-12-16T19:29:33.736084Z","shell.execute_reply":"2023-12-16T19:29:33.745874Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train_pad","metadata":{"execution":{"iopub.status.busy":"2023-12-16T19:29:33.748311Z","iopub.execute_input":"2023-12-16T19:29:33.748695Z","iopub.status.idle":"2023-12-16T19:29:33.759017Z","shell.execute_reply.started":"2023-12-16T19:29:33.748664Z","shell.execute_reply":"2023-12-16T19:29:33.758183Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_train_encoded","metadata":{"execution":{"iopub.status.busy":"2023-12-16T19:29:33.760776Z","iopub.execute_input":"2023-12-16T19:29:33.76113Z","iopub.status.idle":"2023-12-16T19:29:33.772998Z","shell.execute_reply.started":"2023-12-16T19:29:33.761102Z","shell.execute_reply":"2023-12-16T19:29:33.771599Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import EarlyStopping\n\nimport matplotlib.pyplot as plt\n\nimport numpy as np\nimport tensorflow as tf\nfrom sklearn.preprocessing import LabelEncoder\nfrom tensorflow.keras.callbacks import EarlyStopping\n\n\n# # Early stopping callback\n# early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n\n# Train the model\nhistory = model.fit(\n    X_train_pad, y_train_encoded, epochs=20, verbose=True, \n    validation_split=0.2, batch_size=10)\n    \n# Plot training history\nplt.plot(history.history['accuracy'], label='Training Accuracy')\nplt.plot(history.history['val_accuracy'], label='Validation Accuracy')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-12-16T19:29:33.775068Z","iopub.execute_input":"2023-12-16T19:29:33.776033Z","iopub.status.idle":"2023-12-16T19:37:38.283679Z","shell.execute_reply.started":"2023-12-16T19:29:33.775999Z","shell.execute_reply":"2023-12-16T19:37:38.281888Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Results of shallow model**","metadata":{}},{"cell_type":"code","source":"# Model evaluation\nloss, accuracy = model.evaluate(X_train_pad, y_train_encoded, verbose=False)\nprint(\"Training Accuracy: {:.4f}\".format(accuracy))\n\nloss, accuracy = model.evaluate(X_test_pad, y_test_encoded, verbose=False)\nprint(\"Testing Accuracy:  {:.4f}\".format(accuracy))","metadata":{"execution":{"iopub.status.busy":"2023-12-16T19:37:38.284696Z","iopub.status.idle":"2023-12-16T19:37:38.285063Z","shell.execute_reply.started":"2023-12-16T19:37:38.284903Z","shell.execute_reply":"2023-12-16T19:37:38.28492Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Model evaluation\nfrom sklearn.metrics import confusion_matrix, f1_score\nimport seaborn as sns\nimport matplotlib.pyplot as plt\ny_train_pred = (model.predict(X_train_pad) > 0.5).astype(\"int32\")\ny_test_pred = (model.predict(X_test_pad) > 0.5).astype(\"int32\")\n\n# Confusion Matrix\nconf_matrix_train = confusion_matrix(y_train_encoded, y_train_pred)\nconf_matrix_test = confusion_matrix(y_test_encoded, y_test_pred)\n\n# F1 Score\nf1_train = f1_score(y_train_encoded, y_train_pred)\nf1_test = f1_score(y_test_encoded, y_test_pred)\n\n# Plot Confusion Matrix\nfig, axes = plt.subplots(1, 2, figsize=(12, 5))\n\n# Training Set\nsns.heatmap(conf_matrix_train, annot=True, fmt='d', cmap='Blues', cbar=False, ax=axes[0])\naxes[0].set_title('Training Set Confusion Matrix')\naxes[0].set_xlabel('Predicted Label')\naxes[0].set_ylabel('True Label')\n\n# Testing Set\nsns.heatmap(conf_matrix_test, annot=True, fmt='d', cmap='Blues', cbar=False, ax=axes[1])\naxes[1].set_title('Testing Set Confusion Matrix')\naxes[1].set_xlabel('Predicted Label')\naxes[1].set_ylabel('True Label')\n\nplt.show()\n\n# Print F1 Score\nprint(\"Training F1 Score: {:.4f}\".format(f1_train))\nprint(\"Testing F1 Score: {:.4f}\".format(f1_test))","metadata":{"execution":{"iopub.status.busy":"2023-12-16T19:37:38.285925Z","iopub.status.idle":"2023-12-16T19:37:38.28623Z","shell.execute_reply.started":"2023-12-16T19:37:38.286092Z","shell.execute_reply":"2023-12-16T19:37:38.286105Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import precision_score, recall_score\n# Precision and Recall\nprecision_train = precision_score(y_train_encoded, y_train_pred)\nrecall_train = recall_score(y_train_encoded, y_train_pred)\n\nprecision_test = precision_score(y_test_encoded, y_test_pred)\nrecall_test = recall_score(y_test_encoded, y_test_pred)\n\n# Print Precision and Recall\nprint(\"Training Precision: {:.4f}\".format(precision_train))\nprint(\"Training Recall: {:.4f}\".format(recall_train))\n\nprint(\"Testing Precision: {:.4f}\".format(precision_test))\nprint(\"Testing Recall: {:.4f}\".format(recall_test))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **LSTM Model**","metadata":{}},{"cell_type":"markdown","source":"Compiling model","metadata":{}},{"cell_type":"code","source":"from keras.models import Sequential\nfrom keras import layers\nfrom keras.layers import LSTM, Flatten, LeakyReLU\n\nembedding_dim = 100\n\nmodel = Sequential()\nmodel.add(layers.Embedding(vocab_size, embedding_dim, weights=[embedding_matrix], input_length=val, trainable=True))\nmodel.add(LSTM(10, activation='relu'))\nmodel.add(layers.Dense(1, activation='sigmoid'))\nmodel.compile(optimizer='adam',\n              loss='binary_crossentropy',\n              metrics=['accuracy'])\nmodel.summary()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Model Fit**","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import EarlyStopping\n\nimport matplotlib.pyplot as plt\n\nimport numpy as np\nimport tensorflow as tf\nfrom sklearn.preprocessing import LabelEncoder\nfrom tensorflow.keras.callbacks import EarlyStopping\n\n# Train the model\nhistory = model.fit(\n    X_train_pad, y_train_encoded, epochs=20, verbose=True, \n    validation_split=0.2, batch_size=40)\n    \n# Plot training history\nplt.plot(history.history['accuracy'], label='Training Accuracy')\nplt.plot(history.history['val_accuracy'], label='Validation Accuracy')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.legend()\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Results of LSTM Model**","metadata":{}},{"cell_type":"code","source":"# Model evaluation\nloss, accuracy = model.evaluate(X_train_pad, y_train_encoded, verbose=False)\nprint(\"Training Accuracy: {:.4f}\".format(accuracy))\n\nloss, accuracy = model.evaluate(X_test_pad, y_test_encoded, verbose=False)\nprint(\"Testing Accuracy:  {:.4f}\".format(accuracy))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Model evaluation\nfrom sklearn.metrics import confusion_matrix, f1_score\nimport seaborn as sns\nimport matplotlib.pyplot as plt\ny_train_pred = (model.predict(X_train_pad) > 0.5).astype(\"int32\")\ny_test_pred = (model.predict(X_test_pad) > 0.5).astype(\"int32\")\n\n# Confusion Matrix\nconf_matrix_train = confusion_matrix(y_train_encoded, y_train_pred)\nconf_matrix_test = confusion_matrix(y_test_encoded, y_test_pred)\n\n# F1 Score\nf1_train = f1_score(y_train_encoded, y_train_pred)\nf1_test = f1_score(y_test_encoded, y_test_pred)\n\n# Plot Confusion Matrix\nfig, axes = plt.subplots(1, 2, figsize=(12, 5))\n\n# Training Set\nsns.heatmap(conf_matrix_train, annot=True, fmt='d', cmap='Blues', cbar=False, ax=axes[0])\naxes[0].set_title('Training Set Confusion Matrix')\naxes[0].set_xlabel('Predicted Label')\naxes[0].set_ylabel('True Label')\n\n# Testing Set\nsns.heatmap(conf_matrix_test, annot=True, fmt='d', cmap='Blues', cbar=False, ax=axes[1])\naxes[1].set_title('Testing Set Confusion Matrix')\naxes[1].set_xlabel('Predicted Label')\naxes[1].set_ylabel('True Label')\n\nplt.show()\n\n# Print F1 Score\nprint(\"Training F1 Score: {:.4f}\".format(f1_train))\nprint(\"Testing F1 Score: {:.4f}\".format(f1_test))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import precision_score, recall_score\n# Precision and Recall\nprecision_train = precision_score(y_train_encoded, y_train_pred)\nrecall_train = recall_score(y_train_encoded, y_train_pred)\n\nprecision_test = precision_score(y_test_encoded, y_test_pred)\nrecall_test = recall_score(y_test_encoded, y_test_pred)\n\n# Print Precision and Recall\nprint(\"Training Precision: {:.4f}\".format(precision_train))\nprint(\"Training Recall: {:.4f}\".format(recall_train))\n\nprint(\"Testing Precision: {:.4f}\".format(precision_test))\nprint(\"Testing Recall: {:.4f}\".format(recall_test))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **BLSTM Model**","metadata":{}},{"cell_type":"markdown","source":"Model Compile","metadata":{}},{"cell_type":"code","source":"from keras.models import Sequential\nfrom keras import layers\n\nembedding_dim = 100\n\nmodel = Sequential()\nmodel.add(layers.Embedding(vocab_size, embedding_dim, weights=[embedding_matrix], input_length=val, trainable=True))\nmodel.add(layers.Bidirectional(layers.LSTM(10, activation='relu')))\nmodel.add(layers.Dense(1, activation='sigmoid'))\nmodel.compile(optimizer='adam',\n              loss='binary_crossentropy',\n              metrics=['accuracy'])\nmodel.summary()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Model Fit**","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import EarlyStopping\n\nimport matplotlib.pyplot as plt\n\nimport numpy as np\nimport tensorflow as tf\nfrom sklearn.preprocessing import LabelEncoder\nfrom tensorflow.keras.callbacks import EarlyStopping\n\n# Train the model\nhistory = model.fit(\n    X_train_pad, y_train_encoded, epochs=20, verbose=True, \n    validation_split=0.2, batch_size=40)\n    \n# Plot training history\nplt.plot(history.history['accuracy'], label='Training Accuracy')\nplt.plot(history.history['val_accuracy'], label='Validation Accuracy')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.legend()\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Results of BLSTM Model**","metadata":{}},{"cell_type":"code","source":"# Model evaluation\nloss, accuracy = model.evaluate(X_train_pad, y_train_encoded, verbose=False)\nprint(\"Training Accuracy: {:.4f}\".format(accuracy))\n\nloss, accuracy = model.evaluate(X_test_pad, y_test_encoded, verbose=False)\nprint(\"Testing Accuracy:  {:.4f}\".format(accuracy))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Model evaluation\nfrom sklearn.metrics import confusion_matrix, f1_score\nimport seaborn as sns\nimport matplotlib.pyplot as plt\ny_train_pred = (model.predict(X_train_pad) > 0.5).astype(\"int32\")\ny_test_pred = (model.predict(X_test_pad) > 0.5).astype(\"int32\")\n\n# Confusion Matrix\nconf_matrix_train = confusion_matrix(y_train_encoded, y_train_pred)\nconf_matrix_test = confusion_matrix(y_test_encoded, y_test_pred)\n\n# F1 Score\nf1_train = f1_score(y_train_encoded, y_train_pred)\nf1_test = f1_score(y_test_encoded, y_test_pred)\n\n# Plot Confusion Matrix\nfig, axes = plt.subplots(1, 2, figsize=(12, 5))\n\n# Training Set\nsns.heatmap(conf_matrix_train, annot=True, fmt='d', cmap='Blues', cbar=False, ax=axes[0])\naxes[0].set_title('Training Set Confusion Matrix')\naxes[0].set_xlabel('Predicted Label')\naxes[0].set_ylabel('True Label')\n\n# Testing Set\nsns.heatmap(conf_matrix_test, annot=True, fmt='d', cmap='Blues', cbar=False, ax=axes[1])\naxes[1].set_title('Testing Set Confusion Matrix')\naxes[1].set_xlabel('Predicted Label')\naxes[1].set_ylabel('True Label')\n\nplt.show()\n\n# Print F1 Score\nprint(\"Training F1 Score: {:.4f}\".format(f1_train))\nprint(\"Testing F1 Score: {:.4f}\".format(f1_test))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import precision_score, recall_score\n# Precision and Recall\nprecision_train = precision_score(y_train_encoded, y_train_pred)\nrecall_train = recall_score(y_train_encoded, y_train_pred)\n\nprecision_test = precision_score(y_test_encoded, y_test_pred)\nrecall_test = recall_score(y_test_encoded, y_test_pred)\n\n# Print Precision and Recall\nprint(\"Training Precision: {:.4f}\".format(precision_train))\nprint(\"Training Recall: {:.4f}\".format(recall_train))\n\nprint(\"Testing Precision: {:.4f}\".format(precision_test))\nprint(\"Testing Recall: {:.4f}\".format(recall_test))","metadata":{},"execution_count":null,"outputs":[]}]}